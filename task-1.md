# TLDR:

Проектируется не “мессенджер 1:1”, а **платформа сообществ**: 
- пользователь состоит в “сервере” (сообществе), 
- внутри сервера есть каналы (темы), 
- роли/права, 
- модерация, 
- поиск по истории, 
- счётчики непрочитанного и упоминаний. 
Это даёт принципиально другие продуктовые и технические дизайн-выборы, чем у классических чатов.

---

# 1. Тип сервиса и тема:

## Тип сервиса:
Массовый B2C-сервис (web + mobile) для общения и управления сообществами.
## Тема:
"Текстовые каналы и серверы (гильдии): real-time чат для больших сообществ с ролями/правами, историей сообщений, поиском и модерацией".

### Почему это не “обычный мессенджер”
Классический мессенджер (WhatsApp/Telegram-DM) - это в первую очередь **контакты и диалоги** (1:1/группы),
где ключевые сущности: чат, участники, сообщения, доставка.
Discord-подход - это **сообщество -> каналы -> события**, где ключевые сущности: сервер (гильдия), роли,
разрешения/перезапись(overwrites), каналы, упоминания, presence, модерация, поиск, read-states (unread/mentions).

**Технический маркер отличия:** в больших серверах появляется **fan-out на огромное число онлайн-сессий**,
и работа растёт “квадратично” относительно размера сервера (больше людей ->  больше событий -> каждое событие надо разослать большему числу людей).
Это прямо описано в инженерной статье Discord про масштабирование крупных серверов.

---

## 2. Реальные аналоги и рыночная ниша:

**Основной аналог:** Discord - в публичных цифрах Discord заявляет **200M+ глобальных MAU**

**Аналоги по типу “сообщество -> каналы”:**
- **Slack / Microsoft Teams** - те же базовые сущности “workspace/team -> channels -> messages”,
    но ориентированы на корпоративный сегмент (B2B).
    Для нас полезны как proof-of-market, но целевой продукт -> массовый B2C (сообщества).

**Почему ниша существует:** коммуникация внутри сообществ (игры, обучение, open-source, фан-комьюнити) требует:
- разделения по темам (каналы),
- гибких прав (роли + channel overwrites),
- модерации и логов,
- поиска по истории,
- “прочитано/непрочитано” по каждому каналу.
Эти требования плохо закрываются “простыми групповыми чатами”.

---

## 3. Ключевые продуктовые отличия (и как они ломают архитектуру)

Ниже - **дизайн-выборы**, которые отличают “server-based chat” от обычного мессенджера, и почему это важно для backend.

### 3.1. Server-centric модель вместо contact-centric
**Продуктово:** пользователь не “создаёт чат”, а **вступает в сервер**, где уже есть структура каналов/ролей/правил.
**Технически:** сущность membership (user <-> guild) становится базой авторизации, выдачи списка каналов и фильтрации событий.

### 3.2. Каналы как “темы” + сильная локальность данных
**Продуктово:** обсуждения разбиваются на каналы (#announcements, #homework, #memes).
**Технически:** хранение и чтение истории сообщений чаще всего идут **по channel_id**, а не по “chat_id группы”.
    В реальном Discord сообщения партиционируются по каналу + временному bucket, чтобы избегать гигантских партиций
    и “hot partitions”.

### 3.3. Роли + permission overwrites на уровне каналов (ACL-логика)
**Продуктово:** один и тот же сервер может иметь приватные/публичные каналы, уровни доступа, мод-команды и т.п.
**Технически:** каждое событие/сообщение требует **проверки видимости** (кто имеет право видеть канал/сообщение).
    В Discord это делается через комбинацию server-permissions и channel-overwrites (deny/allow в определённом порядке).
    Официальная документация Discord описывает порядок применения разрешений.

**Почему это “сложно”:** в обычном мессенджере “участник чата = видит всё”.
    Тут видимость динамическая и зависит от ролей, которые тоже меняются.

### 3.4. Read-states (unread/mentions) - отдельный “горячий” сервис
**Продуктово:** пользователь ожидает мгновенные счётчики непрочитанного по каждому каналу и отдельные счётчики упоминаний.
**Технически:** это приводит к сущности “Read State = User X Channel”, которая должна обновляться очень часто.
    Discord прямо пишет: Read States - hot path; “billions of Read States”,
    “hundreds of thousands of cache updates per second”, persist в Cassandra.

### 3.5. Массовый real-time fan-out по WebSocket
**Продуктово:** сообщение появляется у всех “онлайн” практически мгновенно.
**Технически:** при отправке сообщения нужно доставить событие многим сессиям; Discord описывает архитектуру
    “guild process как routing point + session process на каждого подключённого клиента”,
    и прямо указывает квадратичную природу нагрузки при больших серверах.
    Также Discord публично описывал масштаб порядка **5,000,000 concurrent users** (сессий) в своей инфраструктуре.

### 3.6. Поиск по истории и модерация как обязательная часть (для сообществ)
**Продуктово:** в сообществах нужна модерация, аудит действий, бан/мьют, удаление сообщений, поиск по ключевым словам.
**Технически:** поиск обычно требует отдельного индекса (например, OpenSearch/Elasticsearch-подобный),
    а модерация - отдельных write-потоков (audit log).

---

## 4. Целевая аудитория (размер и местоположение)

### 4.1. Выбор масштаба аудитории
Ориентир берётся от реального аналога: Discord публично заявляет **200M+ MAU worldwide**.

Для учебного проекта задаём **целевую аудиторию клона**:
- **MAU:** 50M/мес (глобально)
- **DAU:** 10M/день (глобально, минимум по требованию “>=1M / день” выполняется с запасом)
- **Основные регионы:** Северная Америка + Европа (как “первичный рынок”), с дальнейшим глобальным расширением

> DAU выбран как консервативная доля от MAU (stickiness).
> В расчётах ниже DAU - входная гипотеза нагрузки;
> при необходимости можно масштабировать линейно (в 2 раза больше DAU -> в 2 раза больше RPS).

### 4.2. Почему аудитория будет “высоконагруженной”
У Discord-подобных сервисов:
- много событий в real-time (сообщения, реакции, join/leave, presence),
- тяжёлые read-паттерны (скролл истории, обновление read-states),
- огромные “горячие” сообщества, где fan-out становится доминирующей проблемой.

---

## 5) MVP: ключевой функционал (3–7 функций)

Проектируется **MVP, фокус на ядре** (text-channels и серверная логика).

### В MVP входит (7 функций)
1) **Регистрация/логин + сессия** (JWT/refresh, device sessions).
2) **Создание/вступление в сервер по invite-link** (membership).
3) **Список серверов и каналов** (guild list + channel list) с учётом прав.
4) **Чтение истории канала** (pagination: “последние N”, скролл назад).
5) **Отправка сообщения в канал + real-time доставка** (WebSocket events).
6) **Read-states:** непрочитанные каналы + mentions (User X Channel).
7) **Роли/права + базовая модерация + поиск**
   - роли, server permissions, channel overwrites (deny/allow),
   - mute/ban/kick, удаление сообщений,
   - поиск по сообщениям в пределах сервера/канала.

### Вне MVP (осознанно исключаем)
- Voice/video, screen share
- вложения/медиа-хранилище (или оставить как stub)
- боты/SDK, discovery-каталог серверов, платежи/Nitro-подобное
- E2E-шифрование текста (для community-модели это конфликтует с модерацией/поиском)

---

## 6) Продуктовые метрики

### 6.1. North Star Metric (NSM)
**WAU Communicators per Server** - число уникальных пользователей,
    которые **что-то написали/сказали** на сервере за неделю (в среднем по серверам или для топ-серверов).

Почему это хорошая NSM:
- отражает “живость” сообщества, а не просто регистрацию,
- напрямую влияет на нагрузку (writes + fan-out + read states).

### 6.2. Метрики вовлечённости (Discord-подобные)
Discord для владельцев серверов использует понятия:
- **Visitors** - кто кликнул и посмотрел канал,
- **Communicators** - кто писал/говорил,
- **New Member Retention** - кто вернулся через неделю, и даёт бенчмарк “~30% communicators” как “здоровая” цель.

Мы берём эти метрики как продуктовую основу MVP:
- **Visitor -> Communicator conversion** = Communicators / Visitors
- **Activation rate**: доля новых пользователей,
    которые “активировались” (например, просмотрели >=3 каналов или отправили >=1 сообщение - как в Discord-гайде по инсайтам).
- **7-day retention of new members** (D7 retention)

### 6.3. Метрики качества чата (важно для дизайна)
- **p50/p95/p99 latency доставки сообщения (server -> client)**
- **p99 latency открытия канала (history fetch)**
- **доля потерянных real-time событий** (reconnect/replay)
- **moderation actions per 1k messages** (нагрузка модерации)

---

## 7) RPS:

### 7.1. Определение
**RPS (Requests Per Second)** — количество запросов/операций в секунду к сервису (обычно HTTP/gRPC/WS-команды).
Формально:
- `RPS = Requests / Seconds`

Если известны “запросы в день”, то средний RPS:
- `RPS_avg = Requests_per_day / 86400`

Для “действий на пользователя”:
- `Requests_per_day = DAU X Actions_per_user_per_day`
- значит
  `RPS_avg = (DAU X Actions_per_user_per_day) / 86400`

Пиковый RPS (условно):
- `RPS_peak ≈ RPS_avg X PeakFactor`
где `PeakFactor` обычно берут 5 - 10 (вечерние пики, события, крупные релизы).

---

## 8) Расчёт нагрузки

Ниже - **демонстрационный workload-профиль** для MVP. Все числа легко масштабируются (линейно) при смене DAU.

### 8.1. Входные допущения
- `DAU = 10,000,000` пользователей/день
- В день пользователь делает:
  - `C_open = 10` открытий каналов (history fetch + read state)
  - `C_list = 5` запросов “список серверов/каналов” (при старте/переключении)
- Пишущие пользователи (communicators):
  - `Share_comm = 0.30` (30% — ориентир “здоровой доли communicators” из Discord Server Insights)
  - `DAU_comm = DAU X Share_comm = 3,000,000`
  - `M_per_comm = 15` сообщений/день на communicator

> Почему так: в community-чатах основная масса читает, меньшая - пишет.
> Это естественно для “каналов”, и согласуется с visitor/communicator моделью.

### 8.2. RPS для ключевых ручек (API)

#### A) Чтение истории канала (GET /channels/{id}/messages)
- Запросов в день:
  `Req_read = DAU X C_open = 10,000,000 X 10 = 100,000,000 /day`
- Средний RPS:
  `RPS_read_avg = 100,000,000 / 86,400 ≈ 1,157 rps`
- Пик (X10):
  `RPS_read_peak ≈ 11,570 rps`

#### B) Отправка сообщений (POST /channels/{id}/messages)
- Сообщений в день:
  `Msg_day = DAU_comm X M_per_comm = 3,000,000 X 15 = 45,000,000 /day`
- Средний RPS:
  `RPS_send_avg = 45,000,000 / 86,400 ≈ 521 rps`
- Пик (X10):
  `RPS_send_peak ≈ 5,210 rps`

> Важно: это **внешний write-RPS**. Внутри системы одно сообщение превращается
> в **много доставок по WebSocket** (fan-out) и множество обновлений счётчиков - именно это делает архитектуру нетривиальной.

#### C) Список серверов/каналов (GET /me/guilds + GET /guilds/{id}/channels)
- Запросов в день:
  `Req_list = DAU X C_list = 10,000,000 X 5 = 50,000,000 /day`
- Средний RPS:
  `RPS_list_avg = 50,000,000 / 86,400 ≈ 579 rps`
- Пик (X10):
  `RPS_list_peak ≈ 5,790 rps`

### 8.3. Нагрузка “внутренних горячих путей”

#### D) Read-states (UserXChannel) - горячая точка
В Discord описано: Read States - отдельный сервис, “billions of Read States”,
“hundreds of thousands of cache updates per second”,
“tens of thousands of DB writes per second”.

В нашем MVP это означает:
- read-states нельзя делать “в лоб” в одной SQL-таблице без кешей/шардирования,
- нужна стратегия кеширования (LRU/Redis-подобный), батч-коммиты, разделение read/write путей.

#### E) Хранилище сообщений
Discord описывает хранение **триллионов сообщений** и партиционирование по channel+bucket (временные окна),
а также проблемы hot partitions и необходимость request coalescing/consistent hashing к data-service.

В MVP это превращается в дизайн-требование:
- хранить историю так, чтобы чтение “последних сообщений” было быстрым и не убивало одну партицию.

---

## 9) Почему архитектура не тривиальна (критерий курса)

Сервис нетривиален, потому что одновременно присутствуют:
1) **Real-time доставка** (WebSocket gateway + fan-out) и огромная разница между маленькими и гигантскими серверами.
2) **Сложная ACL-логика** (роли + channel overwrites) и фильтрация событий по правам.
3) **Read-states в hot path** и необходимость отдельного сервиса/кешей/батчей.
4) **Поиск и модерация** (индексы, аудит, скорость реакции).
5) **Масштаб хранения** (история сообщений) и проблемы “горячих” партиций.

---

## 10) Требование “минимум 10 серверов”

Даже упрощённый MVP в продакшн-приближении требует разнесения по узлам (пример минимальной раскладки **>=10 машин**):

1–3) **Gateway (WebSocket) X3** - держат постоянные подключения клиентов
4–5) **API (HTTP/gRPC) X2** - auth, guild/channel APIs
6–7) **Message Service X2** - запись/чтение сообщений, coalescing, rate limit
8) **Read-States Service X1** - отдельный hot-path сервис
9) **Search/Index Service X1** - индексирование и поиск
10) **Storage/DB nodes XN** - минимум 1-2 для учебного стенда
    (в реальности - десятки/сотни; у Discord базы сообщений доходили до сотен нод).

> Компонентная модель неизбежно “распухает” за пределы 10 узлов из-за real-time + read-states + storage + search.

---


## 11) Ссылки

> Основные инженерные выводы берутся из официального блога Discord и их страницы “company”.

- https://discord.com/company
- https://discord.com/blog/maxjourney-pushing-discords-limits-with-a-million-plus-online-users-in-a-single-server
- https://pax.discord.com/blog/how-discord-scaled-elixir-to-5-000-000-concurrent-users
- https://discord.com/blog/why-discord-is-switching-from-go-to-rust
- https://discord.com/blog/how-discord-stores-trillions-of-messages
- https://support.discord.com/hc/en-us/articles/214836687-Discord-Roles-and-Permissions
- https://support.discord.com/hc/en-us/articles/206141927-How-is-the-permission-hierarchy-structured
- https://discord.com/community/understanding-server-insights
- https://discord.com/community-manage-engage
- https://discord.com/community/understanding-your-community-through-insights
